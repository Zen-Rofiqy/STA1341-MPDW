---
title: "Time Series Saham NVIDIA dengan Metode ARIMA & ARCH/GARCh"
author: "Angga Fathan Rofiqy"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  rmdformats::downcute:
    self_contained: true
    thumbnails: false
    lightbox: true
    gallery: true
    highlight: tango
    code_folding: hide
    toc_depth: 3
    number_sections: true
    toc_float:
      collapsed: true
      smooth_scroll: true
    fig_caption: true
pkgdown:
  as_is: true
---

Kode di `Hide` dalam *default*, untuk menampilkan kode, klik `Code` .

Analisis sebelum ini : <https://rpubs.com/ZenR_Prog/MPDW-Prak10>

```{r, warning=FALSE, message = FALSE}
#                      -=( Install & Load Package Function )=-
install_load <- function (package1, ...)  {   

   # convert arguments to vector
   packages <- c(package1, ...)

   # start loop to determine if each package is installed
   for(package in packages){

       # if package is installed locally, load
       if(package %in% rownames(installed.packages()))
          do.call('library', list(package))

       # if package is not installed locally, download, then load
       else {
          install.packages(package)
          do.call("library", list(package))
       }
   } 
}

#Path Function
path <- function(){
  gsub  ( "\\\\",  "/",  readClipboard ()  )
}
#Copy path, Panggil function di console
#Copy r path, paste ke var yang diinginkan
```

```{r}
#Export chart
export.chart <- "C:/Users/Fathan/Documents/Obsidian Vault/2. Kuliah/Smt 5/6. Metode Peramalan Deret Waktu/@Proj/STA1341-MPDW/Pertemuan 10/Chart2"
```

# Pendahuluan

## Dataset

![](https://miro.medium.com/v2/resize:fit:1400/1*2Yt3-zcGKc6MYuXCxgCL0A.jpeg)

Dataset yang saya gunakan merupakan koleksi data harga saham historis periode Juli 2018 hingga Juli 2023 dari tujuh raksasa teknologi paling berpengaruh di dunia: Microsoft, Apple, Amazon, Nvidia, Google, Netflix, dan Meta (sebelumnya dikenal sebagai Facebook). Dataset ini menjadi sumber daya berharga bagi analis keuangan, ilmuwan data, dan penggemar pasar saham yang ingin menganalisis dan memahami tren harga perusahaan-perusahaan terkemuka di industri ini.

Dataset ini memilki data :

1.  **Open:** yakni Harga saham pada awal periode perdagangan tertentu. Ini adalah harga saham pertama pada hari perdagangan tersebut.
2.  **High:** Harga tertinggi yang saham capai selama periode perdagangan tersebut. Ini mencerminkan harga tertinggi yang pembeli bersedia bayar selama hari tersebut.
3.  **Low:** Harga terendah yang saham capai selama periode perdagangan tersebut. Ini mencerminkan harga terendah yang penjual bersedia terima selama hari tersebut.
4.  **Close:** Harga saham pada akhir periode perdagangan tertentu. Ini adalah harga saham terakhir pada hari perdagangan tersebut.
5.  **Adj Close (Adjusted Close):** Harga penutup yang telah disesuaikan untuk memperhitungkan perubahan seperti pembagian saham atau dividen. Ini adalah harga penutup yang paling relevan untuk analisis jangka panjang, karena mencerminkan harga saham yang sebenarnya setelah penyesuaian.
6.  **Volume:** Volume perdagangan saham selama periode tertentu. Ini mencerminkan jumlah saham yang diperdagangkan selama hari perdagangan tersebut.

Kami akan menggunakan peubah `Adj Close (Adjusted Close)`, Karena sesuai dengan penjelasan diatas, peubah `Adj Close` adalah yang paling sesuai untuk dianalisis dibandingkan peubah lainnya.

## NVIDIA

Sumber : [finance.yahoo.com](https://finance.yahoo.com/quote/NVDA?p=NVDA){.uri}

Terdapat beberapa faktor yang menjadi landasan dan membuat kami memilih saham **NVIDA**. Berikut adalah latar belakang yang melandasi pemilihan ini:

1.  **Dominasi di Industri Chip AI\
    **NVIDIA Corporation tidak hanya merupakan pemimpin, tetapi juga menggambarkan dominasi dalam industri chip kecerdasan buatan (**AI**). Sejak pendiriannya pada tahun 1993, perusahaan ini telah memainkan peran kunci dalam menghadirkan solusi grafis dan komputasi untuk berbagai industri, termasuk gaming, visualisasi profesional, pusat data, dan otomotif.
2.  **Inovasi Chip H200 sebagai Pemacu Utama\
    **Pengumuman pengembangan chip terbaru, H200, menambahkan dimensi baru pada potensi inovatif NVIDIA dalam mendukung perkembangan AI. Dengan peningkatan signifikan pada memori dan kecepatan, H200 memberikan daya ungkit yang kuat bagi aplikasi AI generatif dan model bahasa besar, menjadikannya subjek yang menarik untuk diteliti.
3.  **Peran Penting dalam Layanan AI Generatif\
    **NVIDIA tidak hanya mendominasi pasar chip AI, tetapi juga memainkan peran penting dalam layanan AI generatif, termasuk layanan ChatGPT yang populer. Sebagai penyedia teknologi di balik berbagai aplikasi AI canggih, perusahaan ini memiliki dampak yang signifikan pada perkembangan dan kemajuan kecerdasan buatan.
4.  **Dukungan dari Cloud Service Providers Terkemuka\
    **Keterlibatan NVIDIA dengan penyedia Cloud Service terkemuka seperti Amazon Web Services, Google Cloud, Microsoft Azure, dan Oracle Cloud Infrastructure menunjukkan pengakuan industri terhadap kualitas dan relevansi produk-produknya. Ini menambah nilai pada data saham NVIDIA sebagai subjek penelitian.
5.  **Performa Saham yang Mengesankan\
    **Kinerja saham NVIDIA yang mengesankan, terutama dengan kenaikan lebih dari tiga kali lipat dalam nilai selama tahun ini, menarik perhatian sebagai indikator potensial untuk menganalisis dampak inovasi teknologinya terhadap nilai pasar saham.

Dengan kombinasi faktor-faktor ini, pemilihan data saham NVIDIA bukan hanya memungkinkan analisis yang mendalam tentang hubungan antara inovasi teknologi dan pergerakan harga saham, tetapi juga memberikan wawasan yang berharga tentang bagaimana **NVIDIA terus memainkan peran krusial dalam perkembangan industri kecerdasan buatan**.

## Tujuan

Tujuan dari praktikum ini adalah untuk menganalisis pola perkiraan pergerakan harga tujuh saham teknologi terkemuka dengan harapan dapat memberikan rekomendasi kepada pembaca mengenai saham mana yang sebaiknya dipertimbangkan untuk dibeli atau diinvestasikan secara signifikan di antara tujuh perusahaan teknologi besar tersebut.

## Data Preparation {.tabset}

### Import Data

```{r, warning=FALSE, message = FALSE}
install_load('rio')
raw.data <- import("https://raw.githubusercontent.com/Zen-Rofiqy/STA1341-MPDW/main/Data/New/%40MAANG%20Stock%20Prices.csv")
```

### Data Checking

Cek Tipe data.

```{r}
str(raw.data)
```

Semua data Karakter, harus diubah.

Cek Data kosong.

```{r}
sum(is.na(raw.data))
```

Tidak ada data kosong.

### Penyesuaian Tipe Data

Semua tipe data masih berupa character. Harus diubah menjadi tipe data yang sesuai.

```{r, warning=FALSE, message = FALSE}
install_load('dplyr')
data <- raw.data %>%  
  mutate(
    Date = as.Date(raw.data[, 2], format = "%m/%d/%y"), #Mengubah menjadi Date 
    across(3:ncol(raw.data), as.numeric)                #Mengubah menjadi Numerik
  )
str(data)
```

### Rechecking DataÂ 

Cek kembali data kosong.

```{r}
cat('Banyaknya Data Kosong', sum(is.na(data)))
```

### Cek Periode Data

```{r message=FALSE, warning=FALSE}
data2 <- data
install_load("lubridate")

dates <- as.Date(data$Date)

# Buat rentang waktu mulai dari tanggal pertama hingga tanggal terakhir dalam data
full_date_range <- seq(min(dates), max(dates), by = "days")

# Bandingkan rentang waktu dengan tanggal yang ada dalam data
missing_dates <- setdiff(full_date_range, dates) 

# Jika 'missing_dates' kosong, maka semua tanggal sudah ada dalam data
if (length(missing_dates) == 0) {
  cat("Semua tanggal ada dalam data.\n")
} else {
  cat("Tanggal yang tidak ada dalam data sebanyak", length(missing_dates),
      "\nAtau sebanyak", length(missing_dates) * 7, 
      "Data Hilang dari ke-7 perusahaan yang ada")
}
```

**Inputasi Data**

```{r fig.align="center", fig.height=9, fig.width=16, message=FALSE, warning=FALSE, dpi=300}
install_load('purrr')
# Fungsi untuk mengisi data yang hilang
fill_missing_data <- function(name) {
  data_filtered <- data2 %>%
    filter(Name == name)
  
  full_date_range <- seq(min(data2$Date), max(data2$Date), by = "days")
  data_frame_template <- data.frame(Date = full_date_range)
  
  # Menambahkan kolom "Name" sesuai dengan perusahaan yang diproses
  data_frame_template$Name <- name
  
  data_filled <- merge(data_frame_template, data_filtered, 
                       by = c("Date", "Name"), all.x = TRUE)
  return(data_filled)
}

# Menggunakan purrr::map untuk memproses setiap nama perusahaan
filled_data_list <- map(unique(data2$Name), fill_missing_data)

# Gabungkan data-data yang telah diisi menjadi satu data frame
final_data <- data.frame()
final_data <- do.call(rbind, filled_data_list)

# Urutkan data berdasarkan "Name" terlebih dahulu, kemudian "Date"
final_data <- final_data %>%
  dplyr::select(1, 2, 7) %>%
  arrange(Name, Date)

#Input Data Hilang
install_load('imputeTS')

data <- na_interpolation(final_data$`Adj Close`)

install_load('ggplot2')
chart <- ggplot_na_imputations(final_data$`Adj Close`, data)
chart
#Export Chart
ggsave("00_Imputasi Data.png", chart, path = export.chart,
        dpi = 300, height = 12, width = 23)

data <- final_data %>% select(Name, Date) %>% 
  mutate(`Adj Close` = data)
```

Data sudah di imputasi.

**Cek ukuran data**

```{r}
cat("Ukuran data awal adalah", nrow(data2),
    "\nBanyaknya peride data yang hilang", length(missing_dates),
    "(PerSaham.", length(missing_dates) * 7, "Jika semua)",
    "\nUkuran data yang baru seharusnya =", 
    nrow(data2) + length(missing_dates) * 7,
    "\nIni sudah sesuai dengan Ukuran data input yakni =", nrow(data))
```

Data sudah benar, siap untuk dianalisis.

### Data Cleaned

```{r message=FALSE, warning=FALSE}
install_load('DT')
datatable(data, filter = 'top', 
          options = list(pageLength = 5))
```

# Eksplorasi Data

Referensi : [Warna1](https://blog.datawrapper.de/colors-for-data-vis-style-guides/){.uri}, [Warna2](https://ux.mailchimp.com/patterns/data#palette){.uri}

```{r}
col.aapl <- c("#6F8086", "#B4CBD2"); col.amzn <- c("#EDB64E", "#F6DEB3") 
col.goog <- c("#919C49", "#CCD775"); col.meta <- c("#4B75BA", "#9BC6EA") 
col.msft <- c("#4EC2C1", "#B8E0DC"); col.nflx <- c("#D02A49", "#F3AEAA") 
col.nvda <- c("#36B450", "#ACD694")

cols <- c("AAPL"=col.aapl[1], "test_aapl"=col.aapl[2],
          "AMZN"=col.amzn[1], "test_amzn"=col.amzn[2],
          "GOOG"=col.goog[1], "test_goog"=col.goog[2],
          "META"=col.meta[1], "test_meta"=col.meta[2],
          "MSFT"=col.msft[1], "test_msft"=col.msft[2],
          "NFLX"=col.nflx[1], "test_nflx"=col.nflx[2],
          "NVDA"=col.nvda[1], "test_nvda"=col.nvda[2] )
```

## Plot Time Series

```{r, warning=FALSE, message = FALSE}
install_load('ggplot2','extrafont')
# font_import(); loadfonts() #Run ini sekali aja
theme.ts <- list(
  theme(legend.position = "none",
        axis.text.x = element_text(hjust = 1, 
                                   margin = margin(b = 10, t=20)),
        axis.text.y = element_text(vjust = 0.5, face = "bold", 
                                   margin = margin(l = 20, r = 20)),
        plot.title = element_text(hjust = 0.5, face = "bold"),
        text = element_text(size = 30),
        plot.subtitle = element_text(hjust = 0.5),
        panel.background = element_rect(fill = 'transparent'),
        plot.background = element_rect(fill='transparent', color=NA),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.line = element_line(linewidth = 1, colour = "black"))
        )
theme.ts1 <- list(
  theme(legend.position = "none",
        axis.text.x = element_text(hjust = 1, 
                                   margin = margin(b = 10, t=20)),
        axis.text.y = element_text(vjust = 0.5, face = "bold", 
                                   margin = margin(l = 50, r = 20)),
        plot.title = element_text(hjust = 0.5, face = "bold"),
        text = element_text(size = 30),
        plot.subtitle = element_text(hjust = 0.5),
        panel.background = element_rect(fill = 'transparent'),
        plot.background = element_rect(fill='transparent', color=NA),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.line = element_line(linewidth = 1, colour = "black"))
        )
```

### MAANG

Melihat keseluruhan *Time Series* data saham.

```{r dpi=300,  fig.height = 12, fig.width = 27, fig.align = "center", warning=FALSE, message = FALSE}
install_load('viridis','ggrepel')
#Plot
chart <-
ggplot(data, aes(x=Date, y=`Adj Close`, color=Name, alpha=Name)) + #Data
  geom_line(aes(color=Name), linewidth=1.5) + #Timeseries
  #Color
  scale_color_manual(values = c(AAPL=col.aapl[1], AMZN=col.amzn[1],
                                GOOG=col.goog[1], META=col.meta[1],
                                MSFT=col.msft[1], NFLX=col.nflx[1], 
                                NVDA=col.nvda[1]) ) +
  scale_alpha_manual(values = c("NVDA" = 1, "NFLX" = .25, "MSFT" = .25, 
                                "META" = .25, "AAPL" = .25, "GOOG" = 1, 
                                "AMZN" = .25)) +
  theme.ts + #THeme
  labs(x = "\nPeriode (Tahun)", y='Harga Saham (USD)',
       title = "Time Series MAANG",
       subtitle = "Seperti apa sih pola deret waktu saham MAANG?\n") +
  # Label / legend
  geom_text_repel(
    data=data[data$Date == max(data$Date),], #Posisi di ujung data
    aes(color = Name, label = Name), #Warna garis & label saham
    size = 8, #Ukuran text
    nudge_x = 80, #Posisi Text (kanan 50)
    hjust = 0, #Ujung
    segment.size = 1,               #Ukuran garis
    segment.alpha = .75,             #transparasi garis
    segment.linetype = "dotted",    #Time garis
    box.padding = .4, #Biar label saham nggak dempetan
    segment.curvature = -0.1, #biar garis mulus
    segment.ncp = 8, 
    segment.angle = 60 
  ) +
  #Axis
    coord_cartesian(clip = "off"
  ) +
    scale_x_date( #Sumbu x
    date_breaks = "1 year",  # Menampilkan label setiap tahun
    date_labels = "%Y",  # Format label tahun
    limits = c(as.Date(min(data$Date)), 
               as.Date(max(data$Date)) + 120)
    #Tampilin lebih dari 20023-07-28 agar label saham bisa masuk
  ) +
    scale_y_continuous( #Sumbu y
    labels = scales::dollar_format(prefix = "$") #tambahin dolar
  ) +
    annotate( #Buat nandain batas data
    "text", x = as.Date(max(data$Date)), y = 50, 
    label = max(data$Date), size=6
  ) +
  geom_vline( #Buat garis batas data
    xintercept = as.numeric(as.Date( max(data$Date) )), 
             linetype = "dotted", color = "red")
chart

#Export Chart
ggsave("01_Time Series MAANG.png", chart, path = export.chart,
        dpi = 300, height = 12, width = 27)
```

Data saham berakhir pada tanggal 28 juli dengan harga saham tertinggi yakni **NVIDIA** dan daham terendah yakni **Google**. Jika dilihat dari tahun `2019-2022`, semua saham cenderung memiliki pola trend naik. Lalu dari `2021-2023` polanya cenderung trend turun. Untuk tugas praktikum kali ini, kami ingin membandingkan pengambilan rentang tahun mana yang lebih baik forcast/peramalannya. Pada Sesi ini hanya akan menggunakan rentang tahun `2022-2023` dengan tren cenderung turun.

```{r}
data2 <- data %>%
  filter(Date >= as.Date("2021-01-01")) 
```

```{r dpi=300,  fig.height = 12, fig.width = 27, fig.align = "center", warning=FALSE, message = FALSE}
install_load('viridis','ggrepel')
#Plot
chart <-
ggplot(data2, aes(x=Date, y=`Adj Close`, color=Name)) + #Data
  geom_line(aes(color=Name), linewidth=1.5) + #Timeseries
  #Color
  scale_color_manual(values = c(AAPL=col.aapl[1], AMZN=col.amzn[1],
                                GOOG=col.goog[1], META=col.meta[1],
                                MSFT=col.msft[1], NFLX=col.nflx[1], 
                                NVDA=col.nvda[1]) ) +
  theme.ts + #THeme
  labs(x = "\nPeriode (Tahun)", y='Harga Saham (USD)',
       title = "Time Series MAANG",
       subtitle = "Seperti apa sih pola deret waktu saham MAANG pada 2021-2023?\n") +
  # Label / legend
  geom_text_repel(
    data=data2[data2$Date == max(data2$Date),], #Posisi di ujung data
    aes(color = Name, label = Name), #Warna garis & label saham
    size = 8, #Ukuran text
    nudge_x = 20, #Posisi Text (kanan 50)
    hjust = 0, #Ujung
    segment.size = 1,               #Ukuran garis
    segment.alpha = .75,             #transparasi garis
    segment.linetype = "dotted",    #Time garis
    box.padding = .4, #Biar label saham nggak dempetan
    segment.curvature = -0.1, #biar garis mulus
    segment.ncp = 8, 
    segment.angle = 60 
  ) +
  #Axis
    coord_cartesian(clip = "off"
  ) +
    scale_x_date( #Sumbu x
    date_breaks = "1 year",  # Menampilkan label setiap tahun
    date_labels = "%Y",  # Format label tahun
    limits = c(as.Date(min(data2$Date)), 
               as.Date(max(data2$Date)) + 120)
    #Tampilin lebih dari 20023-07-28 agar label saham bisa masuk
  ) +
    scale_y_continuous( #Sumbu y
    labels = scales::dollar_format(prefix = "$") #tambahin dolar
  ) +
    annotate( #Buat nandain batas data
    "text", x = as.Date(max(data2$Date)), y = 50, 
    label = max(data2$Date), size=6
  ) +
  geom_vline( #Buat garis batas data
    xintercept = as.numeric(as.Date( max(data2$Date) )), 
             linetype = "dotted", color = "red")
chart

#Export Chart
ggsave("01_Time Series MAANG_2022-2023.png", chart, path = export.chart,
        dpi = 300, height = 12, width = 27)
```

### NVDA

```{r}
nvda <- data2 %>%
  filter(Name == "NVDA")  # Filter data saham Amazon tahun 2022 ke atas

rownames(nvda) <- NULL
str(nvda)
```

```{r}
datatable(nvda, filter = 'top', 
          options = list(pageLength = 5))
```

Mengubah `Ajd Close` Menjadi *Time series.*

```{r}
nvda.ts <- ts(nvda[,3])
```

Ringkasan Data `Ajd CLose.`

```{r}
summary(nvda.ts)
```

```{r fig.align=, fig.height=12, fig.width=27, message=FALSE, warning=FALSE, dpi=300}
min_value <- min(nvda$`Adj Close`)
min_date <- nvda$Date[which.min(nvda$`Adj Close`)]
min_perc <- (which.min(nvda$`Adj Close`) / nrow(nvda)) * 100

max_value <- max(nvda$`Adj Close`)
max_date <- nvda$Date[which.max(nvda$`Adj Close`)]
max_perc <- (which.max(nvda$`Adj Close`) / nrow(nvda)) * 100

chart <-
ggplot(nvda, aes(x=Date, y=`Adj Close`)) + 
  geom_line(aes(color=Name), linewidth=2) +
  scale_color_manual(values = col.nvda[1]) +
  labs(x = "\nPeriode (Tahun)", y='Saham Harga penutup',
       title = "Time Series Saham NVIDIA",
       subtitle = "Seperti apa sih pola deret waktu saham NVIDIA?\n") +
  theme(legend.position = "none") +
  theme.ts1 + 
  
#Ekstras

  #Titik terendah
  geom_segment(aes(x = min_date, 
                   xend = min_date, 
                   y = min(nvda$`Adj Close`)* 1.01, 
                   yend = max(nvda$`Adj Close`)*40/100), 
               arrow = arrow(type = "closed", length = unit(0.1, "inches")), 
               lineend = "round", color = "#D02A49", size=1.5) +
  geom_richtext(
    data = data.frame(x = min_date, 
                      y = max(nvda$`Adj Close`)*40/100, 
                      label = paste0("Titik Terendah") ),
    aes(x, y, label = label), size = 7, color = "white", 
    fill = "#D02A49", box.color = "white", parse = TRUE
  ) +
  geom_text(aes(x = min_date-1*35, y = max(`Adj Close`)*40/100, label = 
                  paste0(min_date)), 
            vjust = -1.5, hjust = 0, size = 7, color = "grey30") +

  #Titik tertinggi
  geom_segment(aes(x = max_date, 
                   xend = max_date, 
                   y = max(nvda$`Adj Close`)* .99, 
                   yend = max(nvda$`Adj Close`)*70/100), 
               arrow = arrow(type = "closed", length = unit(0.1, "inches")), 
               lineend = "round", color = "#4B75BA", size=1.5) +
  geom_richtext(
    data = data.frame(x = max_date, 
                      y = max(nvda$`Adj Close`)*70/100, 
                      label = paste0("Titik Tertinggi") ),
    aes(x, y, label = label), size = 7, color = "white", 
    fill = "#4B75BA", box.color = "white", parse = TRUE
  ) + 
  geom_text(aes(x = max_date-1*35, y = max(`Adj Close`)*60/100, label = 
                  paste0(max_date)), 
            vjust = -1.5, hjust = 0, size = 7, color = "grey30") +
  annotate( #Buat nandain batas data
    "text", x = as.Date(max(data2$Date)) -32, y = 50, 
    label = max(data2$Date), size=6
  ) +
  geom_vline( #Buat garis batas data
    xintercept = as.numeric(as.Date( max(data2$Date) )), 
             linetype = "dotted", color = "red", linewidth=1.5) 

chart
#Export Chart
ggsave("02_Time Series NVIDIA.png", chart, path = export.chart,
        dpi = 300, height = 12, width = 27)
```

Berdasarkan grafik deret waktu yang disajikan, terlihat bahwa dari tahun `2021-2022` terjadi kenaikan harga saham/**tren naik**. Sedangkan `2022-2023` terjadi penurunan harga saham/**tren turun**. Dan pada tahun 2023 akhir tahun terjadi kenaikan harga saham yang drastis/**tren naik**.

### Seasonal

```{r, error=TRUE}
ggseasonplot(nvda.ts)
```

Terlihat bahwa data tidak memiliki pola musiman.

## Data Train vs Test

```{r}
#membagi 80% data latih (training) dan 20% data uji (testing)
train_nvda <- nvda[1: round(nrow(nvda) *78/100),]
test_nvda <- nvda[round(nrow(nvda) *78/100  +1): nrow(nvda),]
train_nvda.ts <- ts(train_nvda[,3])
test_nvda.ts <- ts(test_nvda[,3])
```

```{r fig.align=, fig.height=12, fig.width=27, message=FALSE, warning=FALSE, dpi=300}
chart <-
ggplot() + 
  #Label Data Asli 
  annotate( "rect", alpha=.1, fill="#4EC2C1",
            xmin=as.Date(min(data2$Date)), 
            xmax=as.Date(data2$Date[nrow(train_nvda)]),
            ymin=max(data2$`Adj Close`) * .9, ymax=Inf ) + 
  
  annotate( "text", color="#4EC2C1",
            x = as.Date(data2$Date[ceiling(nrow(train_nvda)/2)]), 
            y = max(data2$`Adj Close`) * .95, 
    label = "Data Latih", size=10) + 
  annotate( "text", color="#4EC2C1",
            x = as.Date(data2$Date[ceiling(nrow(train_nvda)/2)]), 
            y = max(data2$`Adj Close`) * .85, 
    label = paste0(nrow(train_nvda)," Hari (", 
                   round(nrow(train_nvda)/nrow(nvda)*100, 1), 
                   "%)"), size=10) + 
  
  #Label Data Ramal
  annotate( "rect", alpha=.1, fill="violetred",
            xmin=as.Date(data2$Date[nrow(train_nvda)]), 
            xmax=as.Date(max(data2$Date)),
            ymin=max(data2$`Adj Close`) * .9, ymax=Inf ) + 
  
  annotate( "text", color="violetred",
            x = as.Date(data2$Date[ceiling( .89*length(data2$Date)/7)]) , 
            y = max(data2$`Adj Close`) * .95, 
    label = "Data Uji", size=10) +
  annotate( "text", color="violetred",
            x = as.Date(data2$Date[ceiling( .89*length(data2$Date)/7)]) , 
            y = max(data2$`Adj Close`) * .85, 
    label = paste0(nrow(test_nvda)," Hari (", 
                   round(nrow(test_nvda)/nrow(nvda)*100, 1), 
                   "%)"), size=10) +
  
  geom_vline( #Buat garis batas data
    xintercept = as.Date(data2$Date[nrow(train_nvda)]) , 
             linetype = "dotted", color = "black", linewidth = 2) +

#NVDA
  geom_line(data = train_nvda, linewidth=2,
            aes(x = Date, y = `Adj Close`, col = "NVDA")) +
  geom_line(data = test_nvda, linewidth=2,
            aes(x = Date, y = `Adj Close`, col = "test_nvda")) +
  geom_point(data = tail(train_nvda, 1), alpha = .5, 
             aes(x = Date, y = `Adj Close`), stroke=2,
             size = 15, shape = 21, color = "black", fill="violetred") +
  scale_colour_manual(values = cols) +
    theme.ts + #THeme
  labs(x = "\nPeriode (Tahun)", y='Harga Saham (USD)',
       title = "Time Series Saham NVDA",
       subtitle = "Pembagian Data Latih dan data Uji\n") +
  #Axis
    coord_cartesian(clip = "off"
  ) +
    scale_y_continuous( #Sumbu y
    labels = scales::dollar_format(prefix = "$") #tambahin dolar
  ) +

#Bagi Data Train & Test
  geom_segment(aes(x = as.Date(max(train_nvda$Date)), 
                   xend = as.Date(max(train_nvda$Date)), 
                   y = max(nvda$`Adj Close`)* .58, 
                   yend = max(nvda$`Adj Close`)*.7), 
               arrow = arrow(type = "closed", length = unit(0.1, "inches")), 
               lineend = "round", color = "#4B75BA", size=1.5) +
  geom_richtext(
    data = data.frame(x = as.Date(max(train_nvda$Date)), 
                      y = max(nvda$`Adj Close`)*.7, 
                      label = max(train_nvda$Date) ),
    aes(x, y, label = label), size = 8, color = "white", 
    fill = "#4B75BA", box.color = "white", parse = TRUE
  ) +

  geom_segment(aes(x = as.Date(max(data2$Date)), 
                   xend = as.Date(max(data2$Date)), 
                   y = max(nvda$`Adj Close`)* .95, 
                   yend = max(nvda$`Adj Close`)*1.01), 
               arrow = arrow(type = "closed", length = unit(.1, "inches")), 
               lineend = "round", color = "#D02A49", size=1.5) +
  geom_richtext(
    data = data.frame(x = as.Date(max(data2$Date)), 
                      y = max(nvda$`Adj Close`)*1.01, 
                      label = max(data2$Date) ),
    aes(x, y, label = label), size = 8, color = "white", 
    fill = "#D02A49", box.color = "white", parse = TRUE
  )
  
chart
#Export Chart
ggsave("02_TS_NVDA_train-test.png", chart, path = export.chart,
        dpi = 300, height = 12, width = 27)
```

Berdasarkan plot data deret waktu pada data latih ($80\%$ dari data asli), terlihat bahwa data menunjukkan tren turun dan tren naik yang keduanya mulus. Ini mengisyaratkan bahwa data latih **tidak** memenuhi kriteria **stasioneritas dalam rataan maupun ragam**. Di sisi lain, dalam plot data uji ($20\%$ dari data asli), terlihat adanya tren yang melonjak naik dan kurangnya nilai tengah yang stabil. Ini juga menunjukkan bahwa data uji **tidak stasioner dalam rataan**[.]{.underline}

# Stasioneritas

## Uji Stasioneritas

### Plot ACF

```{r fig.align="center", fig.height=3.75, fig.width=7.5, message=FALSE, warning=FALSE, dpi=300}
install_load('tsibble','tseries')
acf(train_nvda.ts, main="", col=col.nvda[1], lwd=2)
mtext("NVDA", side=3, line=1, cex=2, font=2)
```

Berdasarkan plot ACF, terlihat bahwa plot ACF data train menurun secara perlahan (*tails of slowly*). Hal ini juga menjadi indikasi bahwa data **tidak stasioner dalam rataan** dan tidak membentuk gelombang sinus.

```{r, include=FALSE, echo=FALSE}
#Export Chart
png(paste(export.chart, "/03_Stas_1_ACF.png", sep=""),
    height = 3.75*300, width = 7.5*300, res=300)

# Plot 
acf(train_nvda.ts, main="", col=col.nvda[1], lwd=2)
mtext("NVDA", side=3, line=1, cex=2, font=2)

# Menyimpan plot sebagai file PNG
dev.off() # Menutup file PNG
```

### Uji ADF

```{r}
tseries::adf.test(train_nvda.ts)

if (tseries::adf.test(train_nvda.ts)[["p.value"]] < 0.05) {
  cat("Karena p-value < 0.05, Maka Rataan Stasioner")
} else {
  cat("Karena p-value > 0.05, Maka Rataan Tidak Stasioner")
}
```

> $H_0$ : Data tidak stasioner dalam rataan
>
> $H_1$ : Data stasioner dalam rataan

Berdasarkan uji ADF tersebut, *p-value* lebih besar dari taraf nyata $5\%$ sehingga **tak tolak** $H_0$ dan menandakan bahwa data **tidak stasioner dalam rataan**. Hal ini sesuai dengan hasil eksplorasi menggunakan plot time series dan plot ACF, sehingga ketidakstasioneran model kedepannya harus ditangani.

### Plot Box-Cox

```{r fig.align="center", fig.height=3.75, fig.width=7.5, message=FALSE, warning=FALSE, dpi=300}
install_load('MASS')
index <- seq(1:nrow(train_nvda)) #Beda titik potong
bc =boxcox(train_nvda.ts~index, lambda=seq(-2, 4, by=.01))
title("NVDA", cex.main = 2)
lambda_nvda <- bc$x[which.max(bc$y)] #Nilai Rounded Lambda
sk_nvda <- bc$x[bc$y > max(bc$y) - 1/2 * qchisq(.95,1)] #SK
```

Gambar di atas menunjukkan bahwa dari rentang nilai $\lambda$ -2 hingga 4, pada selang yang dibuatnya tidak memuat nilai $\lambda=1$, sehingga ragam tidak stasioner.

```{r, include=FALSE, echo=FALSE}
#Export Chart
png(paste(export.chart, "/03_Stas_2_BoxCox.png", sep=""),
    height = 3.75*300, width = 7.5*300, res=300)

# Plot 
index <- seq(1:nrow(train_nvda)) #Beda titik potong
bc =boxcox(train_nvda.ts~index, lambda=seq(-2, 4, by=.01))
title("NVDA", cex.main = 2)

# Menyimpan plot sebagai file PNG
dev.off() # Menutup file PNG
```

#### Lambda dan Selang Kepercayaan

```{r}
lsk <- data.frame(
  Lambda = c(lambda_nvda ),
  Batas.Bawah = c( min(sk_nvda)  ),
  Batas.Atas = c(max(sk_nvda) )
) %>%
  mutate(across(where(is.numeric), ~round(., 2)))

lsk$Keterangan <- apply(lsk, 1, function(row) {
  ifelse(row["Batas.Bawah"] <= 1 && row["Batas.Atas"] >= 1,
         "Ragam Stasioner",  "Ragam Tidak Stasioner")
})

rownames(lsk) <- c("NVDA")

datatable(lsk, filter = "none")
```

Hal ini dibuktikan dengan tabel nilai *rounded value* ($\lambda$) dan selang kepercayaan diatas yang menyatakan bahwa memuat nilai satu di dalam selangnya. Ini mengindikasikan bahwa `NVDA` memerlukan transformasi data karena **tidak** memiliki sifat **stasioner dalam ragam**.

## **Penanganan Ketidakstasioneran Data**

### Dalam Ragam: Transformasi

Mengutip dari laman [r-coder.com](https://r-coder.com/box-cox-transformation-r/){.uri}, formula transformasi data disesuaikan dengan nilai *rounded value* ($\lambda$) optimumnya.

| $\mathbf{\lambda}$ | **Transformasi** | **Transformasi Balik** |
|:------------------:|:----------------:|:----------------------:|
|         -2         |     $1/x^2$      |      $1/\sqrt{x}$      |
|         -1         |      $1/x$       |         $1/x$          |
|        -0.5        |   $1/\sqrt{x}$   |        $1/x^2$         |
|         0          |   $\log{(x)}$    |         $e^x$          |
|        0.5         |    $\sqrt{x}$    |         $x^2$          |
|         1          |       $x$        |          $x$           |
|         2          |      $x^2$       |       $\sqrt{x}$       |

: Namun dari laman tersebut dan dari laman [robjhyndman.com](https://robjhyndman.com/uwafiles/6-Stationarity-Transformations-Differencing.pdf) mengatakan bahwa *rounded value* ($\lambda$) = 1 itu cenderung tidak ada perubahan substansial atau signifikan yang terjadi pada data. Sehingga jika transformasi diatas tidak menyelesaikan masalah stasioneritas ragam maka **alternatif transfromasi** yang dapat dilakukan adalah dengan $(x^\lambda -1 )/\lambda$ dengan transformasi balik $(\lambda x+1)^{1/\lambda}$.

Sehingga transformasi yang digunakan pada data saham NVDIA adalah sebagai berikut.

```{r}
lamb <- c(-2, -1, -.5, 0, .5, 1, 2)
# Fungsi untuk mengonversi lambda ke transformasi
trans <- function(lambda) {
  lambda <- lamb[sapply(lambda, function(y) which.min(abs(y - lamb))) ]
  case_when(
    lambda == -2   ~ "1/x^2",
    lambda == -1   ~ "1/x",
    lambda == -0.5 ~ "1/sqrt(x)",
    lambda == 0    ~ "log(x)",
    lambda == 1    ~ "x",
    lambda == 0.5  ~ "sqrt(x)",
    lambda == 2    ~ "x^2",
    TRUE           ~ NA_character_
  )
}

# Fungsi untuk mengonversi lambda ke transformasi balik
trans_balik <- function(lambda) {
  lambda <- lamb[sapply(lambda, function(y) which.min(abs(y - lamb))) ]
  case_when(
    lambda == -2   ~ "1/sqrt(x)",
    lambda == -1   ~ "1/x",
    lambda == -0.5 ~ "1/x^2",
    lambda == 0    ~ "exp(x)",
    lambda == 1    ~ "x",
    lambda == 0.5  ~ "x^2",
    lambda == 2    ~ "sqrt(x)",
    TRUE           ~ NA_character_
  )
}

# Menambahkan kolom Transformasi dan Trans Balik
tran <- lsk %>%
  mutate(
    Transformasi = trans(Lambda),
    `Transformasi Balik` = trans_balik(Lambda)
  ) %>% dplyr::select(Lambda, Transformasi, `Transformasi Balik`)

datatable(tran, filter = 'none')
```

#### Transformasi

```{r fig.align="center", fig.height=3.75, fig.width=7.5, message=FALSE, warning=FALSE, dpi=300}
#Transformasi
train_nvda.ts.new <- 1/sqrt(train_nvda.ts)

#Plot BoxCox
index <- seq(1:nrow(train_nvda))
bc <-boxcox(train_nvda.ts.new ~index, lambda=seq(-2, 4, by=.01))
title("NVDA", cex.main=2)
lambda_nvda.new <- bc$x[which.max(bc$y)] #Nilai Rounded Lambda
sk_nvda.new <- bc$x[bc$y > max(bc$y) - 1/2 * qchisq(.95,1)] #SK
```

```{r, include=FALSE, echo=FALSE}
#Export Chart
png(paste(export.chart, "/03_Stas_3_BoxCox.png", sep=""),
    height = 3.75*300, width = 7.5*300, res=300)

# Plot 
index <- seq(1:nrow(train_nvda))
bc <-boxcox(train_nvda.ts.new ~index, lambda=seq(-2, 4, by=.01))
title("NVDA", cex.main=2)

# Menyimpan plot sebagai file PNG
dev.off() # Menutup file PNG
```

```{r}
lsk.new <- data.frame(
  Lambda = c(lambda_nvda.new ),
  Batas.Bawah = c( min(sk_nvda.new)  ),
  Batas.Atas = c( max(sk_nvda.new)  )
) %>%
  mutate(across(where(is.numeric), ~round(., 2)))

lsk.new$Keterangan <- apply(lsk.new, 1, function(row) {
  ifelse(row["Batas.Bawah"] <= 1 && row["Batas.Atas"] >= 1,
         "Ragam Stasioner",  "Ragam Tidak Stasioner")
})

rownames(lsk.new) <- c("NVDA")

datatable(lsk.new, filter = 'none')
```

Setelah melalui proses transformasi, gambar dan tabel di atas mengindikasikan bahwa setiap rangkaian data sekarang mencakup nilai satu dalam selangnya, yang menunjukkan bahwa data tersebut sekarang sudah **stasioner dalam ragam**.

### Dalam Rataan: Differencing

*Differencing* (diferensiasi) adalah suatu proses statistik yang digunakan untuk mengatasi ketidakstasioneran dalam data rata-rata atau tren data. Tujuannya adalah untuk membuat data menjadi lebih stasioner dengan mengurangi atau menghilangkan tren atau pola waktu yang mungkin ada dalam data tersebut.

```{r dpi=300, fig.height = 6, fig.width = 12, fig.align = "center"}
#Diff
train_nvda.diff <- diff(train_nvda.ts.new, differences = 1) 

#Plot
plot.ts(train_nvda.diff, lty=1, xlab="Periode (Tahun)", 
        col = col.nvda[1], lwd = 2,
        main="NVDA", cex.main = 2)
```

Berdasarkan plot data deret waktu yang sudah di *Differencing*, terlihat bahwa seluruh data sudah stasioner dalam rataan ditandai dengan data bergerak pada nilai tengah tertentu (tidak terdapat trend ataupun musiman pada data).

```{r, include=FALSE, echo=FALSE}
#Export Chart
png(paste(export.chart, "/03_Stas_4_Diff.png", sep=""),
    height = 6*300, width = 12*300, res=300)

# Plot 
plot.ts(train_nvda.diff, lty=1, xlab="Periode (Tahun)", 
        col = col.nvda[1], lwd = 2,
        main="NVDA", cex.main = 2)

# Menyimpan plot sebagai file PNG
dev.off() # Menutup file PNG
```

## Uji Ulang

Akan dilakukan uji ulang untuk mengecek kestasioneran data dalam rataan.

### Plot ACF

```{r fig.align="center", fig.height=3.75, fig.width=7.5, message=FALSE, warning=FALSE, dpi=300}
stats::acf(train_nvda.diff, main="", col=col.nvda[1], lwd=2, ylim=c(-.1,.1))
mtext("NVDA", side=3, line=1, cex=2, font=2)
```

Berdasarkan ketujuh plot ACF tersebut, dapat dilihat bahwa lag nya sudah tidak *tails off slowly* (trennya telah berakhir dan korelasi antara pengamatan pada lag-lag yang lebih jauh telah berkurang secara signifikan), sehingga data dinyatakan stasioner dalam rataan. Ini menunjukkan bahwa masalah ketidakstasioneran dalam data telah berhasil diatasi.

```{r, include=FALSE, echo=FALSE}
#Export Chart
png(paste(export.chart, "/03_Stas_5_ACF.png", sep=""),
    height = 3.75*300, width = 7.5*300, res=300)

# Plot 
stats::acf(train_nvda.diff, main="", col=col.nvda[1], lwd=2, ylim=c(-.1,.1))
mtext("NVDA", side=3, line=1, cex=2, font=2)

# Menyimpan plot sebagai file PNG
dev.off() # Menutup file PNG
```

### Uji ADF

```{r message=FALSE, warning=FALSE}
tseries::adf.test(train_nvda.diff)

if (tseries::adf.test(train_nvda.diff)[["p.value"]] < 0.05) {
  cat("Karena p-value < 0.05, Maka Rataan Stasioner")
} else {
  cat("Karena p-value > 0.05, Maka Rataan Tidak Stasioner")
}
```

> $H_0$ : Data tidak stasioner dalam rataan
>
> $H_1$ : Data stasioner dalam rataan

Berdasarkan uji ADF tersebut, *p-value* yang didapatkan yakni lebih kecil dari taraf nyata $5\%$ sehingga **tolak** $H_0$ atau **data stasioner dalam rataan**. Hal ini sesuai dengan hasil eksplorasi menggunakan plot time series dan plot ACF, sehingga dalam hal ini ketidakstasioneran data sudah berhasil ditangani dan dapat dilanjutkan ke pemodelan.

# Model

## Model Tentatif

Identifikasi model tentatif dapat dilakukan dengan melihat pada plot ACF, PACF dan Tabel EACF. Mengutip dari postingan pada laman [medium.com](https://medium.com/@ooemma83/how-to-interpret-acf-and-pacf-plots-for-identifying-ar-ma-arma-or-arima-models-498717e815b6) **Panduan dasar** untuk menginterpretasikan plot ACF dan PACF adalah sebagai berikut :

1.  Cari pola *tail off* pada ACF atau PACF.
2.  Jika *tail off* terjadi pada ACF â **model AR** â *cut off* pada PACF akan memberikan nilai p untuk AR(p).
3.  Jika *tail off* terjadi pada PACF â **model MA** â *cut off* pada ACF akan memberikan nilai q untuk MA(q).
4.  Jika terjadi *tail off* pada kedua ACF dan PACF â **model ARMA**.

### Plot ACF & PACF

```{r fig.align="center", fig.height=4.7, fig.width=15, message=FALSE, warning=FALSE, dpi=300}
par(mfrow=c(1,2))
stats::acf(train_nvda.diff, main="", col=col.nvda[1], lwd=2, ylim=c(-.1,.1))
mtext("NVDA", side=3, line=1, cex=2, font=2)

stats::pacf(train_nvda.diff, main="", col=col.nvda[1], lwd=2, ylim=c(-.1,.1))
mtext("NVDA", side=3, line=1, cex=2, font=2)
```

```{r, include=FALSE, echo=FALSE}
#Export Chart
png(paste(export.chart, "/03_Stas_6_ACF-PACF.png", sep=""),
    height = 4.7*300, width = 15*300, res=300)

# Plot 
par(mfrow=c(1,2))
stats::acf(train_nvda.diff, main="", col=col.nvda[1], lwd=2, ylim=c(-.1,.1))
mtext("NVDA", side=3, line=1, cex=2, font=2)

stats::pacf(train_nvda.diff, main="", col=col.nvda[1], lwd=2, ylim=c(-.1,.1))
mtext("NVDA", side=3, line=1, cex=2, font=2)

# Menyimpan plot sebagai file PNG
dev.off() # Menutup file PNG
```

Referensi : [Significance level of ACF and PACF in R](https://stackoverflow.com/questions/29996910/significance-level-of-acf-and-pacf-in-r){.uri}

```{r}
acf.pacf <- function(dt){ #Fungsi Deteksi Cut off plot ACF & PACF
  N <- acf(dt, plot = F)[["n.used"]] + 1 #Banyaknya Data
  #Garis Signifikan
  sl <- c(-1,1)*(exp(2*1.96/sqrt(N-3))-1)/(exp(2*1.96/sqrt(N-3))+1)
  acf <- data.frame( lag = acf(dt, plot=F)[["lag"]], 
                     acf = acf(dt, plot=F)[["acf"]] ) 
  
    cut.off1 <- acf %>%
        filter(acf <= min(sl) | acf >= max(sl)) %>%
        dplyr::select(lag); colnames(cut.off1) <- "acf"
  
  pacf <- data.frame(lag = pacf(dt, plot=F)[["lag"]], 
                     acf = pacf(dt, plot=F)[["acf"]] ) 
  
    cut.off2 <- pacf %>%
        filter(acf <= min(sl) | acf >= max(sl)) %>%
        dplyr::select(lag); colnames(cut.off2) <- "pacf"
    
  cut.off <- merge(cut.off1, cut.off2, by = 0, all = TRUE)[-1]
  return(cut.off)
}

data_frames <- list(
  train_nvda.diff
)

name <- "NVDA"

acf.pacf.tab <- data.frame()
for(i in 1:length(name)){
  dex <- data_frames[[i]] %>% acf.pacf() %>% 
  rename(!!paste0(name[i], ".a") := acf, 
         !!paste0(name[i], ".p") := pacf)
  
    acf.pacf.tab <- merge(acf.pacf.tab, dex, by=0, all=TRUE)[-1]
}

datatable(acf.pacf.tab, filter = 'none')
```

Berdasarkan plot tersebut, terlihat bahwa plot ACF cut off pada lag 0. Sedangkan pada plot PACF cut off pada lag 14. Sehingga model tidak dapat di identifikasi denganÂ plotÂ ACF.

### Tabel EACF

Referensi : [[University of South Carolina] Chapter 6: Model Specification for Time Series](https://people.stat.sc.edu/hitchcock/stat520ch6slides.pdf){.uri}

> Mengutip dari referensi diatas, Identifikasi model menggunakan Tabel EACF (Extended Autocorrelation Function) untuk proses ARMA(p, q) seharusnya secara teoritis memiliki **pola segitiga nol**, dengan nol di sudut kiri atas muncul pada baris ke-p dan kolom ke-q (dengan label baris dan kolom dimulai dari 0).

Sebagai contoh :

![](images/Screenshot%202023-10-15%20234003-01.png)

Dalam hal ini model tentatif yang terbentuk adalah ARIMA(0,1,1), ARIMA(1,1,1), ARIMA(2,1,2), ARIMA(3,1,3), dst.. Namun karena kemungkinannya sangat banyak, maka akan digunakan function agar menyingkat proses.

Pemilihan model ARIMA terbaik dilakukan ketika memiliki nilai **AIC** yang terkecil, **Semua Parameter Signifikan**, dan **Tidak ada Parameter NA**.

```{r message=FALSE, warning=FALSE}
install_load('TSA', 'forecast')

# Fungsi untuk menghitung model ARIMA dan menganalisis parameter
model_tentatif <- function(data, p_max, d, q_max, alpha=0.05, drift=FALSE) {
  best_model <- NULL
  best_aic <- Inf
  eacf_result <- eacf(data) #Untuk Ektraksi & identifikasi model
  models <- data.frame(Model = character(0), 
                       AIC = numeric(0), 
                       Signif = character(0), 
                       Keterangan = character(0))
  
  for (p in 0:p_max) {
    for (q in 1:q_max) {
      #Pola Matriks segitiga bawah
      if (!is.na(eacf_result$symbol[p + 1, q ]) && 
          !is.na(eacf_result$symbol[p + 1, q + 1]) && 
          !is.na(eacf_result$symbol[p + 2, q + 1])) {
        if (eacf_result$symbol[p + 1, q ] == "o" && 
            eacf_result$symbol[p + 1, q + 1] == "o" && 
            eacf_result$symbol[p + 2, q + 1] == "o") {
      
          model <- Arima(data, order=c(p,d,q), method="ML", 
                         include.drift=drift)
          aic <- AIC(model)
          
          # Mendapatkan nilai coef dari model
          coeftest_result <- lmtest::coeftest(model)
          
          # jika lebih kecil dari alpha, maka signifikan
          significant_params <- 
            rownames(coeftest_result)[coeftest_result[, "Pr(>|z|)"] < alpha]  
          
          # jika lebih besar dari alpha, maka tidak signifikan
          non_significant_params <- 
            rownames(coeftest_result)[coeftest_result[, "Pr(>|z|)"] > alpha]  
          
          # Keterangan signifikansi
          if (length(significant_params) == 0) {
            keterangan <- "Semua parameter tidak signifikan"
          } else if (length(significant_params) == nrow(coeftest_result)) {
            keterangan <- "Semua parameter signifikan"
          } else {
            keterangan <- paste("Parameter yang tidak signifikan adalah", 
                                paste(non_significant_params, collapse = ", "))
          }
          
          models <- rbind(models, 
                    data.frame(Model = paste("ARIMA(", p, ",", d, ",", q, ")", 
                                             sep = ""), 
                               AIC = aic, 
                               Signif = paste(significant_params, 
                                              collapse = ", "), 
                               Keterangan = keterangan))
          
          #Identifikasi Best Model
            if (keterangan == "Semua parameter signifikan" && 
                !any(is.na(significant_params))) {
              if (aic < best_aic) {
                best_model <- model
                best_aic <- aic
            }
          }
          break #jika model ditemukan pada baris p. Maka lanjut ke p+1
        }
      }
    }
  }
  
  cat("\nModel ARIMA dengan AIC terkecil:\n")
  print(best_model)

  return(models)
}
```

```{r message=FALSE, warning=FALSE}
model.tentaif_nvda <- 
  model_tentatif(train_nvda.diff, p_max = 6, d = 1, q_max = 12)
datatable(model.tentaif_nvda, filter = 'top', 
          options = list(pageLength = 7))
```

Berdasarkan pendugaan parameter di atas, nilai AIC terkecil $-8917.35$ dimiliki oleh model `ARIMA(0,1,1)` dan seluruh parameternya signifikan sehingga model yang dipilih adalah model `ARIMA(0,1,1)`.

## Model ARIMA dengan Drift

Tren menentukan bagaimana perubahan deret waktu dari waktu ke waktu. Dalam model ARIMA, ini dapat dimodelkan menggunakan persamaan dasar berikut "a" disebut "**intercept**" dan "b" disebut "**drift**". "Drift" adalah hanyalah kemiringan garis lurus. Selanjutnya akan dilakukan kombinasi model ARIMA dengan Intercept dan Drift.

### 1. Model Tanpa Intercept dan Tanpa Drift

Simpelnya ini merupakan model **data train** yang diberi differencing. Yakni memodelkan data train dengan ordo **I** dari **ARIMA(p, d, q)** sama dengan 1, sehingga kan membentuk model **ARIMA(p, 1, q)**.

```{r message=FALSE, warning=FALSE}
drift1_nvda <- 
  model_tentatif(train_nvda.ts, p_max = 6, d = 1, q_max = 12)
datatable(drift1_nvda, filter = 'top', 
          options = list(pageLength = 7))
```

Berdasarkan pendugaan parameter di atas, nilai AIC terkecil $5063.53$ dimiliki oleh model `ARIMA(4,1,4)` dan seluruh parameternya signifikan sehingga model yang dipilih adalah model `ARIMA(4,1,4)`.

```{r}
model_nvda.drift1 <- Arima(train_nvda.ts, order=c(4,1,4), method="ML")
```

### 2. Model Dengan Intercept Tanpa Drift

Simpelnya ini merupakan model **data differencing** tanpa diberi differencing. Yakni memodelkan data differencing dengan ordo **I** dari **ARIMA(p, d, q)** sama dengan 0, sehingga kan membentuk model **ARIMA(p, 0, q)**.

```{r message=FALSE, warning=FALSE}
drift2_nvda <- 
  model_tentatif(train_nvda.diff, p_max = 6, d = 0, q_max = 12)
datatable(drift2_nvda, filter = 'top', 
          options = list(pageLength = 7))
```

Kategori Model terbaik **tidak ada** yang terpenuhi, yakni tidak ada nilai AIC terkecil dengan semua parameter nya signifikan dan tidak ada NA di dalam nya. Sehingga Model Dengan Intercept Tanpa Drift pada `NVDA` tidak ada.

```{r}
model_nvda.drift2 <- NA
```

### 3. Model Tanpa Intercept Dengan Drift

Simpelnya ini merupakan model **data train** yang diberi **differencing** dan **drift**. Yakni memodelkan data train dengan ordo **I** dari **ARIMA(p, d, q)** sama dengan 1, sehingga kan membentuk model **ARIMA(p, 1, q) + include.drift**.

```{r message=FALSE, warning=FALSE}
drift3_nvda <- 
  model_tentatif(train_nvda.ts, p_max = 6, d = 1, q_max = 12, drift=TRUE)
datatable(drift3_nvda, filter = 'top', 
          options = list(pageLength = 7))
```

Kategori Model terbaik **tidak ada** yang terpenuhi, yakni tidak ada nilai AIC terkecil dengan semua parameter nya signifikan dan tidak ada NA di dalam nya. Sehingga Model Tanpa Intercept Dengan Drift pada `NVDA` tidak ada.

```{r}
model_nvda.drift3 <- NA
```

### 4. Model dengan Intercept dan dengan Drift

Simpelnya ini merupakan model **data differencing** tanpa diberi differencing namun diberi drift. Yakni memodelkan data differencing dengan ordo **I** dari **ARIMA(p, d, q)** sama dengan 0, sehingga kan membentuk model **ARIMA(p, 0, q) + include.drift**.

```{r message=FALSE, warning=FALSE}
drift4_nvda <- 
  model_tentatif(train_nvda.diff, p_max = 6, d = 1, q_max = 12, drift=TRUE)
datatable(drift4_nvda, filter = 'top', 
          options = list(pageLength = 7))
```

Kategori Model terbaik **tidak ada** yang terpenuhi, yakni tidak ada nilai AIC terkecil dengan semua parameter nya signifikan dan tidak ada NA di dalam nya. Sehingga Model dengan Intercept dan dengan Drift pada `NVDA` tidak ada.

```{r}
model_nvda.drift4 <- NA
```

## Model Terbaik

```{r}
model_terbaik <- function(model, rowname, mods) {
  if (!all(is.na(model))) {
    model_df <- data.frame(
      Model = paste("ARIMA(", 
                     paste(as.character(model[["call"]][["order"]][-1]), 
                           collapse = ","), ")", sep = ""),
      AIC = model[["aicc"]],
      row.names = rowname
    )
    model_df$Keterangan <- 
      mods[which(mods$Model == 
                     model_df["Model"][rowname,]), "Keterangan"]
  return(model_df)
    
  } else {
    return(data.frame(
      Model = NA_character_,
      AIC = NA_real_,
      Keterangan = NA_character_,
      row.names = rowname
    ))
  }
}

best_model <- rbind(
  model_terbaik(model_nvda.da, 'NVDA', model.tentaif_nvda),
  model_terbaik(model_nvda.drift1, 'NVDA', drift1_nvda),
  model_terbaik(model_nvda.drift2, 'NVDA', drift2_nvda),
  model_terbaik(model_nvda.drift3, 'NVDA', drift3_nvda),
  model_terbaik(model_nvda.drift4, 'NVDA', drift4_nvda)
) %>%
  mutate(across(where(is.numeric), ~round(., 2)))

datatable(best_model, filter = 'top', 
          options = list(pageLength = 7))
```

Terlihat bahwa model paling terbaik adalah model tentatif tanpa kombinasi drift. Sangat disayangkan, dari 4 kombinasi drift yang ada, hanya kombinasi 1 yang memiliki kategori model terbaik. Sehingga model yang akan digunakan adalah `model_nvda.da`.

# **Analisis Sisaan**

Model terbaik hasil identifikasi kemudian dicek asumsi sisaannya. Sisaan model ARIMA harus memenuhi asumsi normalitas, kebebasan sisaan, dan kehomogenan ragam. Diagnostik model dilakukan secara eksplorasi dan uji formal.

## **Eksplorasi Sisaan**

```{r dpi=300, fig.height = 7, fig.width = 12, fig.align = "center"}
#Eksplorasi 
sisaan_nvda.da <- model_nvda.da$residuals 
par(mfrow=c(2,2)) 
# QQ-Plot
qqnorm(sisaan_nvda.da) 
qqline(sisaan_nvda.da, col = "dodgerblue3", lwd = 2.5) 
# Plot sisaan
plot(c(1:length(sisaan_nvda.da)), sisaan_nvda.da, 
     main = "Plot Sisaan Model ARIMA",
     xlab = "Periode",
     ylab = "Nilai Sisaan")
abline(h = 0, col = "firebrick2", lty = 2, lwd=2.5)
#Plot ACF dan PACF
acf(sisaan_nvda.da, ylim=c(-.1,.1)) 
pacf(sisaan_nvda.da, ylim=c(-.1,.1)) 
```

Berdasarkan plot kuantil-kuantil normal, secara eksplorasi ditunjukkan sisaan menyebar **tidak normal** ditandai dengan tititk-titiknya cenderung tidak mengikuti garis $45^{\circ}$. Kemudian dapat dilihat juga lebar pita sisaan yang cenderung sama menandakan bahwa sisaan memiliki **ragam yang homogen**. Plot ACF dan PACF sisaan `ARIMA(0,1,1)` juga tidak signifikan pada 20 lag awal yang menandakan **saling bebas**. Kondisi ini akan diuji lebih lanjut dengan uji formal.

```{r, include=FALSE, echo=FALSE}
#Export Chart
png(paste(export.chart, "/04_Sisaan_NVDA.png", sep=""),
    height = 7*300, width = 12*300, res=300)

# Plot 
par(mfrow=c(2,2)) 
# QQ-Plot
qqnorm(sisaan_nvda.da) 
qqline(sisaan_nvda.da, col = "dodgerblue3", lwd = 2.5) 
# Plot sisaan
plot(c(1:length(sisaan_nvda.da)), sisaan_nvda.da, 
     main = "Plot Sisaan Model ARIMA",
     xlab = "Periode",
     ylab = "Nilai Sisaan")
abline(h = 0, col = "firebrick2", lty = 2, lwd=2.5)
#Plot ACF dan PACF
acf(sisaan_nvda.da, ylim=c(-.1,.1)) 
pacf(sisaan_nvda.da, ylim=c(-.1,.1))

# Menyimpan plot sebagai file PNG
dev.off() # Menutup file PNG
```

## **Uji Formal** {.tabset}

### Sisaan Menyebar Normal

Selain dengan eksplorasi, asumsi tersebut dapat diuji menggunakan uji formal. Pada tahapan ini uji formal yang digunakan untuk normalitas adalah uji Kolmogorov-Smirnov (KS). Hipotesis pada uji KS adalah sebagai berikut.

> $H_0$ : Sisaan menyebar normal
>
> $H_1$ : Sisaan tidak menyebar normal

```{r}
ks.test(sisaan_nvda.da, "pnorm")

if (ks.test(sisaan_nvda.da, "pnorm")[["p.value"]] < 0.05) {
  cat("Karena p-value < 0.05, Maka Sisaan Tidak Menyebar Normal")
} else {
  cat("Karena p-value > 0.05, Maka Sisaan Menyebar Normal")
}
```

Berdasarkan uji KS tersebut, didapat *p-value* yang sangat kecil yakni kurang dari $2.2\times10^{-16}$. *p-value* nya kurang dari taraf nyata $5\%$ **sehingga tolak** $H_0$ dan menandakan bahwa **sisaan tidak menyebar normal.** Sesuai dengan qqplot sisaan.

### Sisaan saling bebas

Selanjutnya akan dilakukan uji formal untuk kebebasan sisaan menggunakan uji Ljung-Box. Hipotesis yang digunakan adalah sebagai berikut.

> $H_0$ : Sisaan saling bebas
>
> $H_1$ : Sisaan tidak tidak saling bebas

```{r}
Box.test(sisaan_nvda.da, type = "Ljung")

if (Box.test(sisaan_nvda.da, type = "Ljung")[["p.value"]] < 0.05) {
  cat("Karena p-value < 0.05, Maka Sisaan Tidak Saling Bebas")
} else {
  cat("Karena p-value > 0.05, Maka Sisaan Saling Bebas")
}
```

Berdasarkan uji Ljung-Box tersebut, *p-value* nya lebih besar dari taraf nyata $5\%$ sehingga **tak tolak** $H_0$ dan menandakan bahwa **sisaan saling bebas**. Yang berarti tidak ada autokorelasi. Hal ini sesuai dengan hasil eksplorasi menggunakan plot ACF dan PACF.

### Sisaan homogen

Hipotesis yang digunakan untuk uji kehomogenan ragam adalah sebagai berikut.

> $H_0$ : Ragam sisaan homogen
>
> $H_1$ : Ragam sisaan tidak homogen

```{r}
Box.test((sisaan_nvda.da)^2, type = "Ljung")

if (Box.test((sisaan_nvda.da)^2, type = "Ljung")[["p.value"]] < 0.05) {
  cat("Karena p-value < 0.05, Maka Sisaan Tidak Homogen")
} else {
  cat("Karena p-value > 0.05, Maka Sisaan Homogen")
}
```

Berdasarkan uji Ljung-Box terhadap sisaan kuadrat tersebut, *p-value* nya lebih kecil dari taraf nyata $5\%$ sehingga **tolak** $H_0$ dan menandakan bahwa **ragam sisaan tidak homogen**.

### Nilai tengah sama dengan nol

Terakhir, dengan uji-t, akan dicek apakah nilai tengah sisaan sama dengan nol. Hipotesis yang diujikan sebagai berikut.

> $H_0$ : nilai tengah sisaan sama dengan 0
>
> $H_1$ : nilai tengah sisaan tidak sama dengan 0

```{r}
t.test(sisaan_nvda.da, mu=0, conf.level=.95)

if (t.test(sisaan_nvda.da, mu=0, conf.level=.95)[["p.value"]] < 0.05) {
  cat("Karena p-value < 0.05, Maka Nilai Tengah \u2260 0")
} else {
  cat("Karena p-value > 0.05, Maka Nilai Tengah = 0")
}
```

Berdasarkan uji-t tersebut, *p-value* lebih besar dari taraf nyata $5\%$ sehingga **tak tolak** $H_0$ dan menandakan bahwa **nilai tengah sisaan sama dengan nol.**

# Model ARCH-GARCH

Sumber : [Volatility Modeling with R : ARCH and GARCH Models](https://blog.devgenius.io/using-r-to-examine-the-stylized-facts-of-financial-returns-39b86ff4fb4b){.uri}

Model-model tipe ARIMA tidak dapat menjelaskan sejumlah fitur penting yang umum terdapat pada sebagian besar deret waktu. Ada banyak jenis model deret waktu non-linear yang berbeda. Model-model ARCH atau GARCH, yang digunakan untuk memodelkan dan memprediksi volatilitas, merupakan model non-linear yang paling banyak digunakan.

## **1. Efek ARCH**

Penting untuk mempertimbangkan sebuah model yang tidak mengasumsikan bahwa ragam konstan karena dalam kasus deret waktu keuangan, tidak mungkin ragam dari kesalahan akan tetap konstan sepanjang waktu.

Dengan memasukkan **volatilitas bersyarat** daripada asumsi **volatilitas konstan**, model autoregressive conditional heteroskedastisitas (ARCH) diciptakan untuk meningkatkan model ekonometrika.

> Jika ragam dari error tidak konstan, ini disebut sebagai **heteroskedastisitas**. Deret waktu yang menunjukkan heteroskedastisitas bersyarat atau otonomi dalam **deret kuadrat** dikatakan memiliki **efek** autoregressive conditional heteroskedastisitas (**ARCH**).
>
> **Penting untuk menguji Efek ARCH sebelum menerapkan Model ARCH atau GARCH.**

## **2. Uji untuk Efek ARCH**

Lebih masuk akal untuk melakukan uji ARCH Engle (1982) sebelum mengestimasi model tipe GARCH untuk memastikan bahwa kelas model ini sesuai untuk data tersebut.

Uji ARCH Engle merupakan uji multiplier Lagrange untuk menilai signifikansi efek ARCH:

Pertimbangkan pengujian hipotesis:

> $H_0$ : Tidak ada efek ARCH
>
> $H_1$ : Ada efek ARCH

> **Uji ARCH sering diterapkan pada data hasil mentah (raw returns).**

Saat melakukan Uji :

> Jika uji LM menunjukkan nilai p kurang dari $0.05$ , yang menunjukkan bahwa $H_0$ (tanpa efek ARCH) dapat ditolak. Oleh karena itu, log dari hasil saham akan **memiliki efek ARCH**.

atau

> Terapkan Uji Q Ljung-Box pada m lags pertama dari deretan residual kuadrat Sebagai alternatif dari uji ARCH Engle, Anda dapat memeriksa ketergantungan berurutan (efek ARCH) dalam sebuah deret residual dengan melakukan Uji Q Ljung-Box pada m lags pertama dari deretan residual kuadrat.

### Memeriksa keberadaan volatilitas

```{r fig.align=, fig.height=7, fig.width=12, message=FALSE, warning=FALSE, dpi=300}
install_load('fGarch', 'PerformanceAnalytics', 'rugarch', 'xts', 'FinTS')

#calculate log returns and remove first NA value
nvda.z <- zoo(x=nvda$`Adj Close`, order.by=nvda$Date)
Return.nvda <- Return.calculate(nvda.ts, method = "log")[-1]
volatility <- cbind(Return.nvda, Return.nvda^2, abs(Return.nvda))
colnames(volatility) <- c("Returns", "Returns^2", "abs(Returns)")
plot.zoo(volatility, main="NVDA Daily Returns", col="blue")
```

## **3. Engle's ARCH(p) Model**

ARCH, yang merupakan heteroskedastisitas bersyarat, menyatakan bahwa volatilitas tidak konstan, dan berubah hampir sepanjang waktu.

> **Model ARCH(1) adalah model GARCH paling sederhana.**

Dalam model ARCH, 'autokorelasi dalam volatilitas' dimodelkan dengan memperbolehkan ragam bersyarat dari kesalahan untuk bergantung pada nilai sebelumnya secara langsung dari kesalahan kuadrat:

$$ \sigma^2_t = \alpha_0 + \alpha_1 u^2_{t-1} $$

Kasus umum di mana ragam kesalahan bergantung pada q lag dari kesalahan kuadrat, yang dikenal sebagai model ARCH(q):

$$ \sigma^2_t = \alpha_0 + \alpha_1 u^2_{t-1} + \alpha_2 u^2_{t-2} + \dots + \alpha_q u^2_{t-q}  $$

## **4. GARCH(p,q) Models**

Ketika berbicara tentang menangkap pengelompokan volatilitas hasil keuangan, model heteroskedastisitas bersyarat autoregresif umum (GARCH) karya Taylor (1986) dan Bollerslev (1986) mendominasi.

> **Generalized Autoregressive Conditional Heteroskedasticity (GARCH) merupakan penyempurnaan dari model ARCH asli yang dibuat oleh Engle (1986).**

Model GARCH memungkinkan ragam bersyarat bergantung pada lag sendiri sebelumnya dan istilah kesalahan kuadrat.

Model heteroskedastisitas bersyarat autoregresif umum yang paling sederhana dapat dituliskan sebagai:

$$ \sigma^2_t = \alpha_0 + \alpha_1 u^2_{t-1} + \beta \sigma^2_{t-1} $$

Model GARCH(1,1) dapat diperluas menjadi formulasi GARCH(p,q), di mana varians bersyarat saat ini diparameterisasi untuk bergantung pada q lag dari kesalahan kuadrat dan p lag dari varians bersyarat:

$$ \begin{equation} \begin{aligned} \sigma^2_t = &\text{ } \alpha_0 + \alpha_1 u^2_{t-1} + \alpha_2 u^2_{t-2} + \dots + \alpha_q u^2_{t-q} \\ & + \beta_1 \sigma^2_{t-1} + \beta_2 \sigma^2_{t-2} + \dots + \beta_p \sigma^2_{t-p} \\ \sigma^2_t = &\text{ } \alpha_0 + \sum_{i=1}^q \alpha_i u^2_{t-i} + \sum_{j=1}^p \beta_i \sigma^2_{t-i}  \end{aligned} \end{equation} $$

> **Dalam kebanyakan kasus, model GARCH(1,1) sudah cukup untuk menangkap pengelompokan volatilitas dalam data, dan jarang sekali model berorde lebih tinggi diestimasi atau bahkan dipertimbangkan dalam literatur keuangan akademis.**

# **Peramalan**

Peramalan dilakukan menggunakan fungsi `forecast()` . Contoh peramalan berikut ini dilakukan untuk $h$ hari ke depan. Dengan $h$ adalah banyaknya data test per perusahaan.

```{r}
#---FORECAST---#
ramalan_aapl.da <- forecast::forecast(model_aapl.da, h = nrow(test_aapl)) 
ramalan_amzn.da <- forecast::forecast(model_amzn.da, h = nrow(test_amzn)) 
ramalan_goog.da <- forecast::forecast(model_goog.da, h = nrow(test_goog)) 
ramalan_meta.da <- forecast::forecast(model_meta.da, h = nrow(test_meta)) 
ramalan_msft.da <- forecast::forecast(model_msft.da, h = nrow(test_msft)) 
ramalan_nflx.da <- forecast::forecast(model_nflx.da, h = nrow(test_nflx)) 
ramalan_nvda.da <- forecast::forecast(model_nvda.da, h = nrow(test_nvda)) 
```

## Plot Ramalan

```{r dpi=300, fig.height = 8, fig.width = 25, fig.align = "center"}
data.ramalan_aapl.da <- ramalan_aapl.da$mean
data.ramalan_amzn.da <- ramalan_amzn.da$mean
data.ramalan_goog.da <- ramalan_goog.da$mean
data.ramalan_meta.da <- ramalan_meta.da$mean
data.ramalan_msft.da <- ramalan_msft.da$mean
data.ramalan_nflx.da <- ramalan_nflx.da$mean
data.ramalan_nvda.da <- ramalan_nvda.da$mean

#Plot
par(mfrow=c(2,4))
plot(ramalan_aapl.da, main="AAPL", xlab="Periode(Hari)", cex.main=4, 
     lwd=2.5, col="lightskyblue4")
plot(ramalan_amzn.da, main="AMZN", xlab="Periode(Hari)", cex.main=4, 
     lwd=2.5, col = "orange2")
plot(ramalan_goog.da, main="GOOG", xlab="Periode(Hari)", cex.main=4, 
     lwd=2.5, col = "gold3")
plot(ramalan_meta.da, main="META", xlab="Periode(Hari)", cex.main=4, 
     lwd=2.5, col = "dodgerblue3")
plot(ramalan_msft.da, main="MSFT", xlab="Periode(Hari)", cex.main=4, 
     lwd=2.5, col = "deepskyblue2")
plot(ramalan_nflx.da, main="NFLX", xlab="Periode(Hari)", cex.main=4, 
     lwd=2.5, col = "firebrick3")
plot(ramalan_nvda.da, main="NVDA", xlab="Periode(Hari)", cex.main=4, 
     lwd=2.5, col = "green4")
```

Berdasarkan hasil plot ramalan di atas, dapat dilihat bahwa semua ramalan cenderung stabil hingga akhir periode.

```{r dpi=300, fig.height = 7, fig.width = 12, fig.align = "center"}
#Diff inv
ramal_aapl <- diffinv(data.ramalan_aapl.da, differences=1) +
  train_aapl.ts.new[length(train_aapl.ts)]    #nilai akhir data latih

ramal_amzn <- diffinv(data.ramalan_amzn.da, differences=1) +
  train_amzn.ts.new[length(train_amzn.ts)]

ramal_goog <- diffinv(data.ramalan_goog.da, differences=1) +
  train_goog.ts.new[length(train_goog.ts)]

ramal_meta <- diffinv(data.ramalan_meta.da, differences=1) +
  train_meta.ts.new[length(train_meta.ts)]

ramal_msft <- diffinv(data.ramalan_msft.da, differences=1) +
  train_msft.ts.new[length(train_msft.ts)]

ramal_nflx <- diffinv(data.ramalan_nflx.da, differences=1) +
  train_nflx.ts[length(train_nflx.ts)]

ramal_nvda <- diffinv(data.ramalan_nvda.da, differences=1) +
  train_nvda.ts.new[length(train_nvda.ts)]

#Transformasi Balik
ramal_aapl <- 1/(ramal_aapl)^2
ramal_amzn <- (lambda_amzn * (ramal_amzn) + 1)^(1/lambda_amzn)
ramal_goog <- (ramal_goog)^2
ramal_meta <- (lambda_meta * (ramal_meta) + 1)^(1/lambda_meta)
ramal_msft <- 1/(ramal_msft)
ramal_nflx <- (ramal_nflx)
ramal_nvda <- 1/(ramal_nvda)^2

ramal <- data.frame(
  Date = data2 %>% dplyr::select(Date)  ,
  `Adj Close` = c(as.vector(train_aapl.ts), ramal_aapl[-1],
                  as.vector(train_amzn.ts), ramal_amzn[-1],
                  as.vector(train_goog.ts), ramal_goog[-1],
                  as.vector(train_meta.ts), ramal_meta[-1],
                  as.vector(train_msft.ts), ramal_msft[-1],
                  as.vector(train_nflx.ts), ramal_nflx[-1],
                  as.vector(train_nvda.ts), ramal_nvda[-1] ),
  Name = rep(c("AAPL", "AMZN", "GOOG", "META", "MSFT", "NFLX", "NVDA"), 
              each = nrow(train_aapl) + nrow(test_aapl) )
)
colnames(ramal) <- c("Date", "Adj Close", "Name")
```

```{r dpi=300,  fig.height = 12, fig.width = 27, fig.align = "center", warning=TRUE, message = FALSE}
chart <- 
ggplot(ramal, aes(x = Date, y = `Adj Close`, color = Name)) +
  #Label Data Asli 
  annotate( "rect", alpha=0.1, fill="seagreen",
            xmin=as.Date(min(data2$Date)), 
            xmax=as.Date(data2$Date[nrow(train_goog)]),
            ymin=0, ymax=Inf ) + 
  
  annotate( "text", color="seagreen",
            x = as.Date(data2$Date[ceiling(nrow(train_goog)/2)]), 
            y = max(data2$`Adj Close`) * 0.95, 
    label = "Data Asli", size=10) + 
  
  #Label Data Ramal
  annotate( "rect", alpha=0.1, fill="violetred",
            xmin=as.Date(data2$Date[nrow(train_meta)]), 
            xmax=as.Date(max(data2$Date)),
            ymin=0, ymax=Inf ) + 
  
  annotate( "text", color="violetred",
            x = as.Date(data2$Date[ceiling(0.925 * length(data2$Date)/7)]) , 
            y = max(data2$`Adj Close`) * 0.95, 
    label = "Data Ramal", size=10) +
  #Time Series
  geom_line(aes(color=Name), linewidth=1.5) +
#AAPL
  geom_point(data = tail(train_aapl, 1), alpha = .5, 
             aes(x = Date, y = `Adj Close`), stroke=2,
             size = 15, shape = 21, color = "black", fill="violetred") +
#AMZN
  geom_point(data = tail(train_amzn, 1), alpha = .5, 
             aes(x = Date, y = `Adj Close`), stroke=2,
             size = 15, shape = 21, color = "black", fill="violetred") +
#GOOG
  geom_point(data = tail(train_goog, 1), alpha = .5, 
             aes(x = Date, y = `Adj Close`), stroke=2,
             size = 15, shape = 21, color = "black", fill="violetred") +
#META
  geom_point(data = tail(train_meta, 1), alpha = .5, 
             aes(x = Date, y = `Adj Close`), stroke=2,
             size = 15, shape = 21, color = "black", fill="violetred") +
#MSFT
  geom_point(data = tail(train_msft, 1), alpha = .5, 
             aes(x = Date, y = `Adj Close`), stroke=2,
             size = 15, shape = 21, color = "black", fill="violetred") +
#NFLX
  geom_point(data = tail(train_nflx, 1), alpha = .5, 
             aes(x = Date, y = `Adj Close`), stroke=2,
             size = 15, shape = 21, color = "black", fill="violetred") +
#NVDA
  geom_point(data = tail(train_nvda, 1), alpha = .5, 
             aes(x = Date, y = `Adj Close`), stroke=2,
             size = 15, shape = 21, color = "black", fill="violetred") +
  #Warna Saham
  scale_color_manual(values = c(NVDA="green4", NFLX="firebrick3", 
                                MSFT="deepskyblue2", META="dodgerblue3", 
                                AAPL="lightskyblue4",
                                GOOG="gold3", AMZN="orange2") ) +
  theme.ts + #THeme
  labs(x = "\nPeriode (Tahun)", y='Harga Saham (USD)',
       title = "Ramalan Saham MAANG",
       subtitle = "Peramalan Saham MAANG Selama 115 Hari Kedepan\n") +
  # Label / legend
  geom_text_repel(
    data=ramal[ramal$Date == max(ramal$Date),], #Posisi di ujung data
    aes(color = Name, label = Name), #Warna garis & label saham
    size = 8, #Ukuran text
    nudge_x = 20, #Posisi Text (kanan 50)
    hjust = 0, #Ujung
    segment.size = 1,               #Ukuran garis
    segment.alpha = .75,             #transparasi garis
    segment.linetype = "dotted",    #Time garis
    box.padding = .4, #Biar label saham nggak dempetan
    segment.curvature = -0.1, #biar garis mulus
    segment.ncp = 8, 
    segment.angle = 60 
  ) +
  #Axis
    coord_cartesian(clip = "off"
  ) +
    scale_x_date( #Sumbu x
    date_breaks = "1 year",  # Menampilkan label setiap tahun
    date_labels = "%Y",  # Format label tahun
    limits = c(as.Date(min(ramal$Date)), 
               as.Date(max(ramal$Date)) + 60)
  ) +
    scale_y_continuous( #Sumbu y
    labels = scales::dollar_format(prefix = "$") #tambahin dolar
  ) +
    annotate( #Buat nandain batas data
    "text", x = as.Date(max(data2$Date)), y = 50, 
    label = max(data2$Date), size=6
  ) +
  geom_vline( #Buat garis batas data
    xintercept = as.numeric(as.Date( max(data2$Date) )), 
             linetype = "dotted", color = "red") 
chart
#Export Chart
ggsave("09_banding_ramal.png", chart, path = export.chart,
        dpi = 300, height = 12, width = 27)
```

Dapat dilihat bahwa rata-rata harga saham Amazon diramalkan akan cenderung sedikit menurun setiap periodenya. Di sisi lain, saham NVIDIA diramalkan akan menaik pesat setiap periodenya. Sedangkan harga saham lainnya cenderung naik sedikit.

## Perbandingan Data Aktual dengan Data Ramal {.tabset}

### AAPL

```{r}
perbandingan_aapl.da <- matrix(data=c(head(test_aapl.ts, n=nrow(test_aapl)), 
                                      ramal_aapl[-1]),
                     nrow = nrow(test_aapl), ncol = 2)
colnames(perbandingan_aapl.da) <- c("Aktual","Ramal")
datatable(perbandingan_aapl.da, filter = 'top', 
          options = list(pageLength = 5))
```

### AMZN

```{r}
perbandingan_amzn.da <- matrix(data=c(head(test_amzn.ts, n=nrow(test_amzn)), 
                                      ramal_amzn[-1]),
                     nrow = nrow(test_amzn), ncol = 2)
colnames(perbandingan_amzn.da) <- c("Aktual","Ramal")
datatable(perbandingan_amzn.da, filter = 'top', 
          options = list(pageLength = 5))
```

### GOOG

```{r}
perbandingan_goog.da <- matrix(data=c(head(test_goog.ts, n=nrow(test_goog)), 
                                      ramal_goog[-1]),
                     nrow = nrow(test_goog), ncol = 2)
colnames(perbandingan_goog.da) <- c("Aktual","Ramal")
datatable(perbandingan_goog.da, filter = 'top', 
          options = list(pageLength = 5))
```

### META

```{r}
perbandingan_meta.da <- matrix(data=c(head(test_meta.ts, n=nrow(test_meta)), 
                                      ramal_meta[-1]),
                     nrow = nrow(test_meta), ncol = 2)
colnames(perbandingan_meta.da) <- c("Aktual","Ramal")
datatable(perbandingan_meta.da, filter = 'top', 
          options = list(pageLength = 5))
```

### MSFT

```{r}
perbandingan_msft.da <- matrix(data=c(head(test_msft.ts, n=nrow(test_msft)), 
                                      ramal_msft[-1]),
                     nrow = nrow(test_msft), ncol = 2)
colnames(perbandingan_msft.da) <- c("Aktual","Ramal")
datatable(perbandingan_msft.da, filter = 'top', 
          options = list(pageLength = 5))
```

### NFLX

```{r}
perbandingan_nflx.da <- matrix(data=c(head(test_nflx.ts, n=nrow(test_nflx)), 
                                      ramal_nflx[-1]),
                     nrow = nrow(test_nflx), ncol = 2)
colnames(perbandingan_nflx.da) <- c("Aktual","Ramal")
datatable(perbandingan_nflx.da, filter = 'top', 
          options = list(pageLength = 5))
```

### NVDA

```{r}
perbandingan_nvda.da <- matrix(data=c(head(test_nvda.ts, n=nrow(test_nvda)), 
                                      ramal_nvda[-1]),
                               nrow = nrow(test_nvda), ncol = 2)
colnames(perbandingan_nvda.da) <- c("Aktual","Hasil Forecast")
datatable(perbandingan_nvda.da, filter = 'top', 
          options = list(pageLength = 5))
```

## Akurasi

```{r}
akurasi.aapl <- accuracy(ts(ramal_aapl[-1]), 
                         head(test_aapl.ts, n=nrow(test_aapl) )) %>%
  as.data.frame() %>%
  cbind(Model = ramalan_aapl.da[["method"]]) %>% 
  relocate(Model, .before = 1)
row.names(akurasi.aapl) <- "AAPL"

akurasi.amzn <- accuracy(ts(ramal_amzn[-1]), 
                         head(test_amzn.ts, n=nrow(test_amzn) )) %>%
  as.data.frame() %>%
  cbind(Model = ramalan_amzn.da[["method"]]) %>% 
  relocate(Model, .before = 1)
row.names(akurasi.amzn) <- "AMZN"

akurasi.goog <- accuracy(ts(ramal_goog[-1]), 
                         head(test_goog.ts, n=nrow(test_goog) )) %>%
  as.data.frame() %>%
  cbind(Model = ramalan_goog.da[["method"]]) %>% 
  relocate(Model, .before = 1)
row.names(akurasi.goog) <- "GOOG"

akurasi.meta <- accuracy(ts(ramal_meta[-1]), 
                         head(test_meta.ts, n=nrow(test_meta) )) %>%
  as.data.frame() %>%
  cbind(Model = ramalan_meta.da[["method"]]) %>% 
  relocate(Model, .before = 1)
row.names(akurasi.meta) <- "META"

akurasi.msft <- accuracy(ts(ramal_msft[-1]), 
                         head(test_msft.ts, n=nrow(test_msft) )) %>%
  as.data.frame() %>%
  cbind(Model = ramalan_msft.da[["method"]]) %>% 
  relocate(Model, .before = 1)
row.names(akurasi.msft) <- "MSFT"

akurasi.nflx <- accuracy(ts(ramal_nflx[-1]), 
                         head(test_nflx.ts, n=nrow(test_nflx) )) %>%
  as.data.frame() %>%
  cbind(Model = ramalan_nflx.da[["method"]]) %>% 
  relocate(Model, .before = 1)
row.names(akurasi.nflx) <- "NFLX"

akurasi.nvda <- accuracy(ts(ramal_nvda[-1]), 
                         head(test_nvda.ts, n=nrow(test_nvda) )) %>%
  as.data.frame() %>%
  cbind(Model = ramalan_nvda.da[["method"]]) %>% 
  relocate(Model, .before = 1)
row.names(akurasi.nvda) <- "NVDA"
```

```{r}
akurasi <- rbind(akurasi.aapl, akurasi.amzn, akurasi.goog, akurasi.meta,
                 akurasi.msft, akurasi.nflx, akurasi.nvda) %>%
  mutate(Keterangan = case_when(
    MAPE < 10 ~ "Sangat Baik",
    MAPE >= 10 & MAPE <= 20 ~ "Baik",
    MAPE > 20 & MAPE <= 50 ~ "Layak",
    MAPE > 50 ~ "Tidak Akurat"
  )) %>% relocate(Keterangan, Model, MAPE)

datatable(akurasi, filter = 'top', 
          options = list(pageLength = 7))
```

Dari tabel diatas terlihat bahwa model **ARIMA(0,1,1)** Merupakan model yang paling sering digunakan. Model dengan kategori *"Sangat baik"* hanya ada di `GOOG` (**ARIMA(4,1,5)**) dan `MSFT` (**ARIMA(4,1,5)**). Di sisi lain, model dengan katergori *"Baik"* ada pada `NFLX` (**ARIMA(6,1,7)**) dan `NVDA` (**ARIMA(0,1,1)**). Sisanya mendapatkan kategori *"Layak".*

# Penutup

```{r, warning=FALSE, message = FALSE}
#Export Data
install_load('openxlsx')
#Model Tentatif 
write.xlsx(list("AAPL" = model.tentaif_aapl, 
                "AMZN" = model.tentaif_amzn, 
                "GOOG" = model.tentaif_goog, 
                "META" = model.tentaif_meta, 
                "MSFT" = model.tentaif_msft, 
                "NFLX" = model.tentaif_nflx, 
                "NVDA" = model.tentaif_nvda), 
           file = "Model_Tentatif.xlsx")

# 1. Model Tanpa Intercept dan Tanpa Drift
write.xlsx(list("AAPL" = drift1_aapl, 
                "AMZN" = drift1_aapl, 
                "GOOG" = drift1_aapl, 
                "META" = drift1_aapl, 
                "MSFT" = drift1_aapl, 
                "NFLX" = drift1_aapl, 
                "NVDA" = drift1_aapl), 
           file = "Model_Drift1.xlsx")

# 2. Model Dengan Intercept Tanpa Drift 
write.xlsx(list("AAPL" = drift2_aapl, 
                "AMZN" = drift2_aapl, 
                "GOOG" = drift2_aapl, 
                "META" = drift2_aapl, 
                "MSFT" = drift2_aapl, 
                "NFLX" = drift2_aapl, 
                "NVDA" = drift2_aapl), 
           file = "Model_Drift2.xlsx")

# 3. Model Tanpa Intercept Dengan Drift
write.xlsx(list("AAPL" = drift3_aapl, 
                "AMZN" = drift3_aapl, 
                "GOOG" = drift3_aapl, 
                "META" = drift3_aapl, 
                "MSFT" = drift3_aapl, 
                "NFLX" = drift3_aapl, 
                "NVDA" = drift3_aapl), 
           file = "Model_Drift3.xlsx")

# 4. Model dengan Intercept dan dengan Drift
write.xlsx(list("AAPL" = drift4_aapl, 
                "AMZN" = drift4_aapl, 
                "GOOG" = drift4_aapl, 
                "META" = drift4_aapl, 
                "MSFT" = drift4_aapl, 
                "NFLX" = drift4_aapl, 
                "NVDA" = drift4_aapl), 
           file = "Model_Drift4.xlsx")
```

## Referensi

-   [Forecasting: Principles and Practice](https://otexts.com/fpp2/){.uri}, *Rob J Hyndman and George Athanasopoulos.* Monash University, Australia.

-   [BOOSTEDML : Time series](https://boostedml.com/category/time-series){.uri}, Articles on Statistics and Machine Learning for Healthcare.
